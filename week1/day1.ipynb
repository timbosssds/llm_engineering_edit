{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3574312c-3638-4550-adba-d947167c8f01",
   "metadata": {},
   "source": [
    "__Date:__ 27.12.24<br>\n",
    "__Note:__ Didn't get all of it to run, but got the key parts going (prob due to\n",
    "using flash as opposed to GPT). Key part between markers - '-- Key parts --'. They key part is scraping content from websites.\n",
    "\n",
    "<br>\n",
    "\n",
    "__Part ii__: At the end, there is an output from Week 3 day 5.\n",
    "__Note:__ There they are using tokenizer. I wanted to simplify that.\n",
    "The cool thing they did was use a model to convert speech to text. Thats where this kicks of\n",
    "it takes the text, then passes that to llm to get meeting notes. Looks high quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44e4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Instant Gratification\n",
    "\n",
    "## Your first Frontier LLM Project!\n",
    "\n",
    "Let's build a useful LLM solution - in a matter of minutes.\n",
    "\n",
    "By the end of this course, you will have built an autonomous Agentic AI solution with 7 agents that collaborate to solve a business problem. All in good time! We will start with something smaller...\n",
    "\n",
    "Our goal is to code a new kind of Web Browser. Give it a URL, and it will respond with a summary. The Reader's Digest of the internet!!\n",
    "\n",
    "Before starting, you should have completed the setup for [PC](../SETUP-PC.md) or [Mac](../SETUP-mac.md) and you hopefully launched this jupyter lab from within the project root directory, with your environment activated.\n",
    "\n",
    "## If you're new to Jupyter Lab\n",
    "\n",
    "Welcome to the wonderful world of Data Science experimentation! Once you've used Jupyter Lab, you'll wonder how you ever lived without it. Simply click in each \"cell\" with code in it, such as the cell immediately below this text, and hit Shift+Return to execute that cell. As you wish, you can add a cell with the + button in the toolbar, and print values of variables, or try out variations.  \n",
    "\n",
    "I've written a notebook called [Guide to Jupyter](Guide%20to%20Jupyter.ipynb) to help you get more familiar with Jupyter Labs, including adding Markdown comments, using `!` to run shell commands, and `tqdm` to show progress.\n",
    "\n",
    "## If you'd prefer to work in IDEs\n",
    "\n",
    "If you're more comfortable in IDEs like VSCode or Pycharm, they both work great with these lab notebooks too.  \n",
    "If you'd prefer to work in VSCode, [here](https://chatgpt.com/share/676f2e19-c228-8012-9911-6ca42f8ed766) are instructions from an AI friend on how to configure it for the course.\n",
    "\n",
    "## If you'd like to brush up your Python\n",
    "\n",
    "I've added a notebook called [Intermediate Python](Intermediate%20Python.ipynb) to get you up to speed. But you should give it a miss if you already have a good idea what this code does:    \n",
    "`yield from {book.get(\"author\") for book in books if book.get(\"author\")}`\n",
    "\n",
    "## I am here to help\n",
    "\n",
    "If you have any problems at all, please do reach out.  \n",
    "I'm available through the platform, or at ed@edwarddonner.com, or at https://www.linkedin.com/in/eddonner/ if you'd like to connect (and I love connecting!)\n",
    "\n",
    "## More troubleshooting\n",
    "\n",
    "Please see the [troubleshooting](troubleshooting.ipynb) notebook in this folder to diagnose and fix common problems. At the very end of it is a diagnostics script with some useful debug info.\n",
    "\n",
    "## If this is old hat!\n",
    "\n",
    "If you're already comfortable with today's material, please hang in there; you can move swiftly through the first few labs - we will get much more in depth as the weeks progress.\n",
    "\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Please read - important note</h2>\n",
    "            <span style=\"color:#900;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you do this with me, either at the same time, or (perhaps better) right afterwards. Add print statements to understand what's going on, and then come up with your own variations. If you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business value of these exercises</h2>\n",
    "            <span style=\"color:#181;\">A final thought. While I've designed these notebooks to be educational, I've also tried to make them enjoyable. We'll do fun things like have LLMs tell jokes and argue with each other. But fundamentally, my goal is to teach skills you can apply in business. I'll explain business implications as we go, and it's worth keeping this in mind: as you build experience with models and techniques, think of ways you could put this into action at work today. Please do contact me if you'd like to discuss more or if you have ideas to bounce off me.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "#from openai import OpenAI\n",
    "\n",
    "# If you get an error running this cell, then please head over to the troubleshooting notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900b2a8-6384-4316-8aaa-5e519fca4254",
   "metadata": {},
   "source": [
    "# Connecting to OpenAI\n",
    "\n",
    "The next cell is where we load in the environment variables in your `.env` file and connect to OpenAI.\n",
    "\n",
    "## Troubleshooting if you have problems:\n",
    "\n",
    "Head over to the [troubleshooting](troubleshooting.ipynb) notebook in this folder for step by step code to identify the root cause and fix it!\n",
    "\n",
    "If you make a change, try restarting the \"Kernel\" (the python process sitting behind this notebook) by Kernel menu >> Restart Kernel and Clear Outputs of All Cells. Then try this notebook again, starting at the top.\n",
    "\n",
    "Or, contact me! Message me or email ed@edwarddonner.com and we will get this to work.\n",
    "\n",
    "Any concerns about API costs? See my notes in the README - costs should be minimal, and you can control it at every point. You can also use Ollama as a free alternative, which we discuss during Day 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b87cadb-d513-4303-baee-a37b6f938e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "#elif not api_key.startswith(\"sk-proj-\"):\n",
    "elif not api_key.startswith(\"A*\"):    \n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019974d9-f3ad-4a8a-b5f9-0a3719aea2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "\n",
    "# If this doesn't work, try Kernel menu >> Restart Kernel and Clear Outputs Of All Cells, then run the cells from the top of this notebook down.\n",
    "# If it STILL doesn't work (horrors!) then please see the Troubleshooting notebook in this folder for full instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442fc84b-0815-4f40-99ab-d9a5da6bda91",
   "metadata": {},
   "source": [
    "# Let's make a quick call to a Frontier model to get started, as a preview!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a58394bf-1e45-46af-9bfd-01e24da6f49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!  Welcome!  It's nice to meet you too!  How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To give you a preview -- calling OpenAI with these messages is this easy. Any problems, head over to the Troubleshooting notebook.\n",
    "\n",
    "message = \"Hello, GPT! This is my first ever message to you! Hi!\"\n",
    "# response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\":\"user\", \"content\":message}])\n",
    "# print(response.choices[0].message.content)\n",
    "\n",
    "# ---- using Gem instead ----\n",
    "# Validate i can call the llm\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key= api_key)\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\",\n",
    "  generation_config=generation_config,)\n",
    "\n",
    "chat_session = model.start_chat(\n",
    "  history=[  ])\n",
    "\n",
    "response = chat_session.send_message(message)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa190e5-cb31-456a-96cc-db109919cd78",
   "metadata": {},
   "source": [
    "## OK onwards with our first project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db37c99e-5658-4953-83e5-151191fb5d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a9114f9-fbe3-4862-ae86-d8b5251249b6",
   "metadata": {},
   "source": [
    "#### --------------- Key parts ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5e793b2-6775-426a-a139-4848291d0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2ef960cf-6dc2-4cda-afb3-b38be12f4c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shree Sita Ram Mandir  \n"
     ]
    }
   ],
   "source": [
    "# Let's try one out. Change the website and add print statements to follow along.\n",
    "\n",
    "#ed = Website(\"https://edwarddonner.com\")\n",
    "ed = Website(\"https://www.shreesitarammandir.com/\")\n",
    "#ed = Website(\"https://www.news.com.au/\")\n",
    "print(ed.title)\n",
    "#print(ed.text)\n",
    "ed1 = ed.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "561bd128-5e23-4133-9984-fa83098cb0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Shree Sita Ram Mandir Website Summary\n",
      "\n",
      "The Shree Sita Ram Mandir website offers information on Hindu festivals and observances, including key dates for 2024 and 2025,  and guidance on puja (worship) and bhakti (devotion).  It provides resources such as the Ramayan and Chalisa, and information on various Vrats (religious observances).  The site encourages devotees to submit questions and suggestions via the contact page and features links to recordings of the 2023 Akhand Ramayan on Facebook.  A Hindi proverb emphasizes the importance of satsang (good company) and divine grace for spiritual understanding.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# t1s\n",
    "\n",
    "message = f\"\"\"You are an assistant that analyzes the contents of a website \n",
    "that will be prrovided as text that has already been scrapped from the site in question. \\\n",
    "Your task is to provide a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown. Here is the contents of the website (provided as text) {ed1}\"\"\"\n",
    "\n",
    "\n",
    "response = chat_session.send_message(message)\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff8b1a0-14c3-48cc-81f0-b741795c40cc",
   "metadata": {},
   "source": [
    "#### --------------- Key parts ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd5d5e-96f4-44a9-8f8f-31b51bae1c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112da40d-e515-4b4b-953e-c09cf699ced5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a478a0c-2c53-48ff-869c-4d08199931e1",
   "metadata": {},
   "source": [
    "## Types of prompts\n",
    "\n",
    "You may know this already - but if not, you will get very familiar with it!\n",
    "\n",
    "Models like GPT4o have been trained to receive instructions in a particular way.\n",
    "\n",
    "They expect to receive:\n",
    "\n",
    "**A system prompt** that tells them what task they are performing and what tone they should use\n",
    "\n",
    "**A user prompt** -- the conversation starter that they should reply to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abdb8417-c5dc-44bc-9bee-2e059d162699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0275b1b-7cfe-4f9d-abfa-7650d378da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26448ec4-5c00-4204-baec-7df91d11ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(user_prompt_for(ed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea211b5f-28e1-4a86-8e52-c0b7677cadcc",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "The API from OpenAI expects to receive messages in a particular structure.\n",
    "Many of the other APIs share this structure:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]\n",
    "\n",
    "To give you a preview, the next 2 cells make a rather simple call - we won't stretch the might GPT (yet!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f25dcd35-0cd0-4235-9f64-ac37ed9eaaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a snarky assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21ed95c5-7001-47de-a36d-1d6673b403ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi!  Welcome!  I hope you have a great experience interacting with me.  What brings you here today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To give you a preview -- calling OpenAI with system and user messages:\n",
    "\n",
    "#response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "#print(response.choices[0].message.content)\n",
    "\n",
    "response = chat_session.send_message(message)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e8d78-ce4c-4b05-aa8e-17050c82bb47",
   "metadata": {},
   "source": [
    "## And now let's build useful messages for GPT-4o-mini, using a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0134dfa4-8299-48b5-b444-f2a8c3403c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36478464-39ee-485c-9f3f-6a4e458dbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this out, and then try for a few more websites\n",
    "#messages_for(ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "00277d53-23b6-4936-a0aa-7f45158cdb2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# t1s\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#print(system_prompt)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m website\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://edwarddonner.com\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43muser_prompt_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwebsite\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[28], line 8\u001b[0m, in \u001b[0;36muser_prompt_for\u001b[1;34m(website)\u001b[0m\n\u001b[0;32m      4\u001b[0m     user_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are looking at a website titled \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwebsite\u001b[38;5;241m.\u001b[39mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m     user_prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThe contents of this website is as follows; \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124mplease provide a short summary of this website in markdown. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124mIf it includes news or announcements, then summarize these too.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m     user_prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mwebsite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m user_prompt\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# t1s\n",
    "#print(system_prompt)\n",
    "\n",
    "website=\"https://edwarddonner.com\"\n",
    "print(user_prompt_for(website))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f49d46-bf55-4c3e-928f-68fc0bf715b0",
   "metadata": {},
   "source": [
    "## Time to bring it together - the API for OpenAI is very simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "905b9919-aba7-45b5-ae65-81b3d1d78e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "# def summarize(url):\n",
    "#     website = Website(url)\n",
    "#     response = openai.chat.completions.create(\n",
    "#         model = \"gpt-4o-mini\",\n",
    "#         messages = messages_for(website)\n",
    "#     )\n",
    "#     return response.choices[0].message.content\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = chat_session.send_message(\n",
    "        #message)# = messages_for(website)\n",
    "        messages_for(website))\n",
    "    #)\n",
    "    return response.text\n",
    "\n",
    "# response = chat_session.send_message(message)\n",
    "# print(response.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05e38d41-dfa4-4b20-9c96-c46ea75d9fb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['role', 'content']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msummarize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://edwarddonner.com\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[58], line 13\u001b[0m, in \u001b[0;36msummarize\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msummarize\u001b[39m(url):\n\u001b[0;32m     12\u001b[0m     website \u001b[38;5;241m=\u001b[39m Website(url)\n\u001b[1;32m---> 13\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mchat_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#message)# = messages_for(website)\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwebsite\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m#)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[1;32m~\\desktop\\bt\\AIEng\\llm_engineering\\.venv\\Lib\\site-packages\\google\\generativeai\\generative_models.py:564\u001b[0m, in \u001b[0;36mChatSession.send_message\u001b[1;34m(self, content, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported configuration: The `google.generativeai` SDK currently does not support the combination of `stream=True` and `enable_automatic_function_calling=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m     )\n\u001b[0;32m    562\u001b[0m tools_lib \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_get_tools_lib(tools)\n\u001b[1;32m--> 564\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[43mcontent_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m content\u001b[38;5;241m.\u001b[39mrole:\n\u001b[0;32m    567\u001b[0m     content\u001b[38;5;241m.\u001b[39mrole \u001b[38;5;241m=\u001b[39m _USER_ROLE\n",
      "File \u001b[1;32m~\\desktop\\bt\\AIEng\\llm_engineering\\.venv\\Lib\\site-packages\\google\\generativeai\\types\\content_types.py:296\u001b[0m, in \u001b[0;36mto_content\u001b[1;34m(content)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m content\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, Iterable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m protos\u001b[38;5;241m.\u001b[39mContent(parts\u001b[38;5;241m=\u001b[39m[\u001b[43mto_part\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m content])\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;66;03m# Maybe this is a Part?\u001b[39;00m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m protos\u001b[38;5;241m.\u001b[39mContent(parts\u001b[38;5;241m=\u001b[39m[to_part(content)])\n",
      "File \u001b[1;32m~\\desktop\\bt\\AIEng\\llm_engineering\\.venv\\Lib\\site-packages\\google\\generativeai\\types\\content_types.py:247\u001b[0m, in \u001b[0;36mto_part\u001b[1;34m(part)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_part\u001b[39m(part: PartType):\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(part, Mapping):\n\u001b[1;32m--> 247\u001b[0m         part \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(part, protos\u001b[38;5;241m.\u001b[39mPart):\n\u001b[0;32m    250\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m part\n",
      "File \u001b[1;32m~\\desktop\\bt\\AIEng\\llm_engineering\\.venv\\Lib\\site-packages\\google\\generativeai\\types\\content_types.py:176\u001b[0m, in \u001b[0;36m_convert_dict\u001b[1;34m(d)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m protos\u001b[38;5;241m.\u001b[39mBlob(blob)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to determine the intended type of the `dict`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor `Content`, a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m key is expected. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor `Part`, either an \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline_data\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m key is expected. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor `Blob`, both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmime_type\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keys are expected. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHowever, the provided dictionary has the following keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(d\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m     )\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['role', 'content']\""
     ]
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d926d59-450e-4609-92ba-2d6f244f1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3018853a-445f-41ff-9560-d925d1774b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hi!  Welcome!  I'm ready when you are.  What's on your mind?\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bcf6f4-adce-45e9-97ad-d9a5d7a3a624",
   "metadata": {},
   "source": [
    "# Let's try more websites\n",
    "\n",
    "Note that this will only work on websites that can be scraped using this simplistic approach.\n",
    "\n",
    "Websites that are rendered with Javascript, like React apps, won't show up. See the community-contributions folder for a Selenium implementation that gets around this. You'll need to read up on installing Selenium (ask ChatGPT!)\n",
    "\n",
    "Also Websites protected with CloudFront (and similar) may give 403 errors - many thanks Andy J for pointing this out.\n",
    "\n",
    "But many websites will work just fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "45d83403-a24c-44b5-84ac-961449b4008f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hi there!  Welcome!  It's nice to e-meet you.  What can I help you with today?  Let's have a great conversation!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e9fd40-b354-4341-991e-863ef2e59db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951be1a-7f1b-448f-af1f-845978e47e2c",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business applications</h2>\n",
    "            <span style=\"color:#181;\">In this exercise, you experienced calling the Cloud API of a Frontier Model (a leading model at the frontier of AI) for the first time. We will be using APIs like OpenAI at many stages in the course, in addition to building our own LLMs.\n",
    "\n",
    "More specifically, we've applied this to Summarization - a classic Gen AI use case to make a summary. This can be applied to any business vertical - summarizing the news, summarizing financial performance, summarizing a resume in a cover letter - the applications are limitless. Consider how you could apply Summarization in your business, and try prototyping a solution.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you continue - now try yourself</h2>\n",
    "            <span style=\"color:#900;\">Use the cell below to make your own simple commercial example. Stick with the summarization use case for now. Here's an idea: write something that will take the contents of an email, and will suggest an appropriate short subject line for the email. That's the kind of feature that might be built into a commercial email tool.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00743dac-0e70-45b7-879a-d7293a6f68a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create your prompts\n",
    "\n",
    "system_prompt = \"something here\"\n",
    "user_prompt = \"\"\"\n",
    "    Lots of text\n",
    "    Can be pasted here\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Make the messages list\n",
    "\n",
    "messages = [] # fill this in\n",
    "\n",
    "# Step 3: Call OpenAI\n",
    "\n",
    "response =\n",
    "\n",
    "# Step 4: print the result\n",
    "\n",
    "print("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed9f14-b349-40e9-a42c-b367e77f8bda",
   "metadata": {},
   "source": [
    "## An extra exercise for those who enjoy web scraping\n",
    "\n",
    "You may notice that if you try `display_summary(\"https://openai.com\")` - it doesn't work! That's because OpenAI has a fancy website that uses Javascript. There are many ways around this that some of you might be familiar with. For example, Selenium is a hugely popular framework that runs a browser behind the scenes, renders the page, and allows you to query it. If you have experience with Selenium, Playwright or similar, then feel free to improve the Website class to use them. In the community-contributions folder, you'll find an example Selenium solution from a student (thank you!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab24dc-5f90-4570-b542-b0585aca3eb6",
   "metadata": {},
   "source": [
    "# Sharing your code\n",
    "\n",
    "I'd love it if you share your code afterwards so I can share it with others! You'll notice that some students have already made changes (including a Selenium implementation) which you will find in the community-contributions folder. If you'd like add your changes to that folder, submit a Pull Request with your new versions in that folder and I'll merge your changes.\n",
    "\n",
    "If you're not an expert with git (and I am not!) then GPT has given some nice instructions on how to submit a Pull Request. It's a bit of an involved process, but once you've done it once it's pretty clear. As a pro-tip: it's best if you clear the outputs of your Jupyter notebooks (Edit >> Clean outputs of all cells, and then Save) for clean notebooks.\n",
    "\n",
    "Here are good instructions courtesy of an AI friend:  \n",
    "https://chatgpt.com/share/677a9cb5-c64c-8012-99e0-e06e88afd293"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682eff74-55c4-4d4b-b267-703edbc293c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dfb9c5b",
   "metadata": {},
   "source": [
    "# Part ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f13beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is from Week 3 day 5.\n",
    "# That code uses tokeizers (good to know, but not needing to use right now) so,\n",
    "# running here to see how it goes with Flash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69cd4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This was the code to convert speech to text. Not sure it would work here as needs hugging face. \n",
    "# # Could get it working, if wanted to... \n",
    "\n",
    "# # Define the model path\n",
    "# AUDIO_MODEL = \"openai/whisper-medium\"\n",
    "\n",
    "# # Load the model and processor\n",
    "# speech_model = AutoModelForSpeechSeq2Seq.from_pretrained(AUDIO_MODEL, torch_dtype=torch.float16, low_cpu_mem_usage=True, use_safetensors=True)\n",
    "# speech_model.to('cuda')\n",
    "# processor = AutoProcessor.from_pretrained(AUDIO_MODEL)\n",
    "\n",
    "# # Set up the pipeline with return_timestamps=True\n",
    "# pipe = pipeline(\n",
    "#     \"automatic-speech-recognition\",\n",
    "#     model=speech_model,\n",
    "#     tokenizer=processor.tokenizer,\n",
    "#     feature_extractor=processor.feature_extractor,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     device='cuda',\n",
    "#     return_timestamps=True  # Enable timestamp prediction for long-form audio\n",
    "# )\n",
    "\n",
    "# # Use the Whisper OpenAI model to convert the Audio to Text\n",
    "# result = pipe(audio_filename)\n",
    "\n",
    "# transcription = result[\"text\"]\n",
    "# print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a9c8b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = \"and kind of the confluence of this whole idea of the Confluence Week, the merging of two rivers. And as we've kind of seen recently in politics and in the world, there's a lot of situations where water is very important right now, and it's a very big issue. So that is the reason that the back of the logo is considered water. So let me see the creation of the logo here. Yeah, so that basically kind of sums up the reason behind the logo and all the meanings behind the symbolism. And you'll hear a little bit more about our Confluence Week is basically highlighting all of these indigenous events and things that are happening around Denver so that we can kind of bring more people together and kind of share this whole idea of Indigenous Peoples Day. So thank you. Thank you so much and thanks for your leadership. All right. Welcome to the Denver City Council meeting of Monday, October 9th. Please rise with the Pledge of Allegiance by Councilman Lopez. I pledge allegiance to the flag of the United States of America, and to the republic for which it stands, one nation under God, indivisible, with liberty and justice for all. All right, thank you, Councilman Lopez, Madam Secretary Rockall. Black. Clerk. Here. Espinosa. Here. Flynn. Gilmore? Here. Here. Cashman? Here. Canich? Here. Lopez? Here. New? Here. Ortega? Here. Sussman? Here. Mr. President? Here. Eleven present. Eleven members present. We do have a quorum. Approval of the minutes. Are there any corrections to the minutes of October 2nd? Seeing none, minutes of October 2nd stand approved. Council announcements. Are there any announcements by members of council? Councilman Clark. Thank you, Mr. President. I just wanted to invite everyone down to the first ever Halloween parade on Broadway in Lucky District 7. It will happen on Saturday, October 21st at 6 o'clock p.m. It'll move along Broadway from third to Alameda. It's gonna be a fun, family-friendly event. Everyone's invited to come down, wear a costume. There'll be candy for the kids, and there are tiki zombies and 29 hearse's, and all kinds of fun and funky stuff on the fun and funky part of Broadway. So please join us October 21st at six o'clock for the Broadway Halloween bread. Thank you, Mr. President. All right, thank you, Councilman Clark. I will be there. All right, presentations. Madam Secretary, do we have any presentations? None, Mr. President. Communications, do we have any communications? None, Mr. President. We do have one proclamation this evening, Proclamation 1127, an observance of the annual Indigenous Peoples Day in the city and county of Denver. Councilman Lopez, will you please read it? Thank you, Mr. President, with pride. Proclamation number 17, well, let me just say this differently, Proclamation number 1127, series of 2017, an observance of the second annual Indigenous Peoples Day in the City and County of Denver. Whereas the Council of the City and County of Denver recognizes that the indigenous peoples have lived and flourished on the lands known as the Americas since time immemorial. And that Denver and the surrounding communities are built upon the ancestral homelands of numerous indigenous tribes which include the Southern Ute, the Ute Mountain, tribes of Colorado and whereas the tribal homelands and seasonal encampments of the Arapahoe and Cheyenne people along the banks of the Cherry Creek and South Platte River confluence gave bearing to the future settlements that would become the birthplace of the Mile High City. And whereas Colorado encompasses the ancestral homelands of 48 tribes and the city and county of Denver and surrounding communities are home to the descendants of approximately 100 tribal nations. And whereas on October 3rd 2016 the City and County of Denver unanimously passed Council Bill 801 series of 2016 officially designating the second Monday of October of each year as Indigenous Peoples Day in Denver Colorado. And whereas the Council of the City and County of Denver continues to recognize and value the vast contributions made to the community through Indigenous peoples knowledge, science, philosophy, arts and culture and through these contributions the City of Denver has developed and thrived. Whereas the Indigenous community especially youth have made great efforts this year to draw attention to the contributions of Indigenous people including Confluence week, drawing record attendance to a national Indigenous youth leadership conference, leading conversations on inclusion with their peers and supporting increased Indigenous youth participation in science and engineering. Now therefore, be it proclaimed by the Council of the City and County of Denver, Section 1, that the Council of the City and County of Denver celebrates and honours the cultural and foundational contributions of Indigenous people to our history, our past, our present and future, and continues to promote the education of the Denver community about these historic and contemporary contributions of Indigenous people. Section 2, that the City and County of Denver, Colorado does hereby observe October 9, 2017 as Indigenous Peoples' Day. Section 3, that The clerk of the city and county of Denver shall attest and affix the seal of the city and county of Denver to this proclamation and that a copy be transmitted to the Denver American Indian Commission, the city and county of Denver School District Number One, and the Colorado Commission on Indian Affairs. Thank you. Councilman Lopez, your motion to adopt. Mr. President, I move that proclamation number 1127, series of 2017 be adopted. All right, it has been moved and seconded. It comes with a move to council. Councilman Lopez. Thank you, Mr. President. It gives me a lot of pleasure and pride to read this proclamation officially for the third time, but as Indigenous Peoples Day in Denver officially for the second time. It's always awesome to be able to see not just this proclamation come by my desk, but to see so many different people from our community in our council chambers. It was a very beautiful piece of artwork that you presented to us earlier, and it is exactly the spirit that we drafted this proclamation, and this actual, the ordinance that created Indigenous Peoples Day, when we sat down and wrote it, and as a community, we couldn't think of anything else to begin, except for the confluence of the two rivers. And those confluence of the two rivers created such a great city. And we live in such an amazing city. And we're all proud of it. And sometimes we, and a lot of people from all over the country or all over the world are proud of it. And sometimes a little too proud of it is telling them to go back home. But I'm kidding when I say that. But the really nice thing about this is that we are celebrating Indigenous People's Day out of pride for who we are, who we are as a city and the contributions of indigenous people to the city, not out of spite, not out of a replacement of one culture over the other, or out of contempt or disrespect. I think of a quote that Cesar Chavez made very popular, and it stuck with me for a very long time. And anytime I have the opportunity, I speak in front of children, and especially children in our community that, you know, they often second-guess themselves on where they're coming from, who they are. And I always say that, you know, it's very important to be proud of who you're from. And the quote that I use from Cesar Chavez is, you know, pride in one's own culture does does not require contempt or disrespect of another. Right? And that's very important. It's very important for us to recognize that, no matter who we are, where we come from in this society, that your pride in your own culture does not require the contempt or disrespect of another. And man, what a year for that to sit on our shoulders for a while, for us to think about. Right? And so I wanted to just to thank you all, I think the commission, there's gonna be a couple individuals that are gonna come speak. Thank you for your art, your lovely artwork, for us to see what's in your heart and what now has become, probably is gonna be a very important symbol for the community. And also just for the work, the daily work every single day. We still have a lot of brothers and sisters whose ancestors once lived in these lands freely now stand on street corners, right, in poverty, without access to services, right, without access to sobriety or even housing or jobs, and what a cruel way to pay back a culture that has paved the way for the city to be built upon its shores, right? So we have a lot of work to do, and these kind of proclamations in this day It's not a day off, it's a day on in Denver, right? And addressing those critical issues. So I know that my colleagues are very supportive. I'm gonna ask you to support this proclamation as I know you always have done in the past. I'm very proud of today. Oh, and we made Time Magazine and Newsweek once again. Today, as being a leader in terms of the cities that are celebrating Indigenous Peoples Day. I wanted to make a point out of that. Thank you, Councilman Lopez, and thank you for sponsoring this. Councilman Martega. Mr. President, I wanna ask that my name be added. I don't think I could add much more to what Councilman Lopez has shared with us. I wanna thank him for bringing this forward, and really just appreciate all the contributions that our Native American community has contributed to this great city and great state. I worked in the Lieutenant Governor's Office when the Commission on Indian Affairs was created and had the benefit of being able to go down to the Four Corners for a peace treaty signing ceremony between the Utes and the Comanches that had been sort of at odds with each other for about 100 years, and just being able to participate in that powwow was pretty awesome. And for those of you who continue to participate in the annual powwow. It's such a great opportunity for everybody else to enjoy so many of the contributions of the culture. I mean, to see that the dance continues to be carried on as well as the native language from generation to generation is just so incredible because in so many cultures, people have come here and assimilated to the norms here you know, the norms here and they lose their language and lose a lot of the culture. And in the Native community, that hasn't happened. That has, that, you know, commitment to just passing that on from generation to generation is so important. And so I'm happy to be a co-sponsor of this tonight. Thank you. All right, thank you, Councilwoman Ortega. Councilwoman Kenich. Thank you very much, and I also wanna thank my colleague for bringing this forward. And I just wanted to say a word to the artist about how beautiful and moving I thought this logo was and your description of it. And I think one of the things that is clear is, you know, the words sometimes don't convey the power of imagery or music or the other pieces that make up culture, and so I think the art is so important. And when you talked about water, I was also thinking about land, and I guess I just wanted to say thank you. Many of the Native American peoples of Colorado have been at the forefront, or actually nationally, of defending some of the public lands that have been protected over the last few years that are under attack right now. And they're places that you all, the communities have fought to protect, but that everyone gets to enjoy. And so I just think that it's an example of where cultural preservation intersects with environmental protection, with recreation and all of the other ways that public lands are so important. And so I think I just wanted to say thank you for that because I think we have some very sacred places in our country that are at risk right now. And so as we celebrate, I appreciate that there's still a piece of resistance in here and I think that I just wanna mention a solidarity. And I mentioned a feeling of solidarity with that resistance. So thank you and happy Confluence Week. Thank you, Councilman Kenich. Seeing no other comments, I'll just say a couple. In a time of such divisive ugliness and just despicable behavior from our leadership, the reason I'm so supportive of Indigenous Peoples' Day is because it means inclusivity. It means respecting all, respecting those who have been silenced on purpose for a long time and whose history has not been told. And so we celebrate inclusivity in the face of such evil times, honestly.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bddcd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that produces minutes of meetings from transcripts, with summary, key discussion points, takeaways and action items with owners, in markdown.\"\n",
    "user_prompt = f\"Below is an extract transcript of a Denver council meeting. Please write minutes in markdown, including a summary with attendees, location and date; discussion points; takeaways; and action items with owners.\\n{transcription}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "975d723c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Denver City Council Meeting Minutes\n",
       "\n",
       "**Meeting Summary:**\n",
       "\n",
       "* **Date:** Monday, October 9th, 2017\n",
       "* **Location:** Denver City Council Chambers\n",
       "* **Attendees:**  Council members Black, Clerk, Espinosa, Flynn, Gilmore, Cashman, Canich, Lopez, New, Ortega, Sussman, and President (name not specified in transcript).\n",
       "* **Purpose:** Approval of minutes, council announcements, presentations (none), communications (none), and proclamation of Indigenous Peoples' Day.\n",
       "\n",
       "**Key Discussion Points:**\n",
       "\n",
       "* **Approval of Minutes:** Minutes from October 2nd meeting were approved without correction.\n",
       "* **Council Announcements:** Councilman Clark announced the first annual Halloween parade in the Lucky District 7 on Broadway, October 21st at 6:00 PM.\n",
       "* **Proclamation 1127: Observance of Indigenous Peoples' Day:**  The council unanimously adopted Proclamation 1127, officially observing October 9th, 2017, as Indigenous Peoples' Day in Denver.  The proclamation acknowledges the historical and ongoing contributions of Indigenous peoples to the city, highlighting the significance of the confluence of the Cherry Creek and South Platte Rivers and the ancestral lands of numerous tribes.  Council members praised the accompanying artwork and emphasized the importance of celebrating Indigenous culture with pride and inclusivity, not as a replacement or denigration of other cultures.  Concerns were raised about the ongoing challenges faced by many Indigenous people in the city, including poverty and lack of access to services. The city's recognition of Indigenous Peoples' Day was also noted as being highlighted in Time Magazine and Newsweek.  The symbolism of water in the logo, representing the confluence of rivers and the importance of water as a resource, was discussed.  Council members also highlighted Confluence Week as an event highlighting Indigenous events and bringing people together.\n",
       "\n",
       "**Takeaways:**\n",
       "\n",
       "* The Denver City Council demonstrated a strong commitment to recognizing and celebrating Indigenous Peoples' Day and the contributions of Indigenous communities.\n",
       "* The proclamation underscored the importance of inclusivity and respect for all cultures.\n",
       "* The discussion highlighted the need for continued work to address the social and economic disparities faced by Indigenous people in Denver.\n",
       "* The artwork presented showcased the cultural significance and symbolism of the Indigenous community.\n",
       "* The council members recognized the importance of the confluence of the Cherry Creek and South Platte rivers in the city's history and the ancestral lands of various Indigenous tribes.\n",
       "\n",
       "\n",
       "**Action Items:**\n",
       "\n",
       "| Action Item                                         | Owner             | Due Date       | Status |\n",
       "|-----------------------------------------------------|--------------------|-----------------|--------|\n",
       "| Transmit a copy of Proclamation 1127 to the Denver American Indian Commission, the Denver School District #1, and the Colorado Commission on Indian Affairs. | City Clerk        | Immediately     |Open    |\n",
       "| Continued work to address social and economic disparities faced by Indigenous people in Denver. | Denver City Council | Ongoing         | Open    |\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To give you a preview -- calling OpenAI with these messages is this easy:\n",
    "\n",
    "message = system_message + user_prompt\n",
    "# response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\":\"user\", \"content\":message}])\n",
    "# print(response.choices[0].message.content)\n",
    "\n",
    "# ---- using Gem instead ----\n",
    "# Validate i can call the llm\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key= api_key)\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\",\n",
    "  generation_config=generation_config,)\n",
    "\n",
    "chat_session = model.start_chat(\n",
    "  history=[  ])\n",
    "\n",
    "response = chat_session.send_message(message)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3abd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2127f62b",
   "metadata": {},
   "outputs": [],
   "source": []
=======
>>>>>>> origin/main
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
