{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01023030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to day 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe37963-1af6-44fc-a841-8e462443f5e6",
   "metadata": {},
   "source": [
    "## Expert Knowledge Worker\n",
    "\n",
    "### A question answering agent that is an expert knowledge worker\n",
    "### To be used by employees of Insurellm, an Insurance Tech company\n",
    "### The agent needs to be accurate and the solution should be low cost.\n",
    "\n",
    "This project will use RAG (Retrieval Augmented Generation) to ensure our question/answering assistant has high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba2779af-84ef-4227-9e9e-6eaf0df87e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "802137aa-8a74-45e0-a487-d1974927d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for langchain\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c85082-e417-4708-9efe-81a5d55d1424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged these two and replaced with gem below\n",
    "# # price is a factor for our company, so we're going to use a low cost model\n",
    "# MODEL = \"gpt-4o-mini\"\n",
    "# db_name = \"vector_db\"\n",
    "\n",
    "# # Load environment variables in a file called .env\n",
    "# load_dotenv()\n",
    "# os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8fc1e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There might be a problem with your API key? Please visit the troubleshooting notebook!\n",
      "Understood.  I'm ready for your test.  Please proceed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "# MODEL = 'gpt-4o-mini'\n",
    "# openai = OpenAI()\n",
    "\n",
    "# ----- Replacing with Gem code -----\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key= api_key)\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "  #\"response_mime_type\": \"application/json\",\n",
    "\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\",\n",
    "  generation_config=generation_config,)\n",
    "\n",
    "chat_session = model.start_chat(\n",
    "  history=[  ])\n",
    "\n",
    "message = \"this is a test only\"\n",
    "response = chat_session.send_message(message)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "730711a9-6ffe-4eee-8f48-d6cfb7314905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in documents using LangChain's loaders\n",
    "# Take everything in all the sub-folders of our knowledgebase\n",
    "\n",
    "folders = glob.glob(\"knowledge-base/*\")\n",
    "\n",
    "# With thanks to CG and Jon R, students on the course, for this fix needed for some users \n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "# If that doesn't work, some Windows users might need to uncomment the next line instead\n",
    "# text_loader_kwargs={'autodetect_encoding': True}\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "252f17e9-3529-4e81-996c-cfa9f08e75a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e8decb0-d9b0-4d51-8402-7a6174d22159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'knowledge-base\\\\employees\\\\Oliver Spencer.md', 'doc_type': 'employees'}, page_content='# HR Record\\n\\n# Oliver Spencer\\n\\n## Summary\\n- **Date of Birth**: May 14, 1990  \\n- **Job Title**: Backend Software Engineer  \\n- **Location**: Austin, Texas  \\n\\n## Insurellm Career Progression\\n- **March 2018**: Joined Insurellm as a Backend Developer I, focusing on API development for customer management systems.\\n- **July 2019**: Promoted to Backend Developer II after successfully leading a team project to revamp the claims processing system, reducing response time by 30%.\\n- **June 2021**: Transitioned to Backend Software Engineer with a broader role in architecture and system design, collaborating closely with the DevOps team.\\n- **September 2022**: Assigned as the lead engineer for the new \"Innovate\" initiative, aimed at integrating AI-driven solutions into existing products.\\n- **January 2023**: Awarded a mentorship role to guide new hires in backend technology and best practices within Insurellm.\\n\\n## Annual Performance History\\n- **2018**: **3/5** - Adaptable team player but still learning to take initiative.\\n- **2019**: **4/5** - Demonstrated strong problem-solving skills, outstanding contribution on the claims project.\\n- **2020**: **2/5** - Struggled with time management; fell behind on deadlines during a high-traffic release period.\\n- **2021**: **4/5** - Made a significant turnaround with organized work habits and successful project management.\\n- **2022**: **5/5** - Exceptional performance during the \"Innovate\" initiative, showcasing leadership and creativity.\\n- **2023**: **3/5** - Maintaining steady work; expectations for innovation not fully met, leading to discussions about goals.\\n\\n## Compensation History\\n- **March 2018**: Initial salary of $80,000.\\n- **July 2019**: Salary increased to $90,000 post-promotion.\\n- **June 2021**: Salary raised to $105,000 after role transition.\\n- **September 2022**: Salary adjustment to $120,000 due to increased responsibilities and performance.\\n- **January 2023**: Revised salary of $125,000 in recognition of mentorship role.\\n\\n## Other HR Notes\\n- Oliver enjoys a strong rapport with team members and is known for organizing regular team-building activities.\\n- Participated in Insurellm’s Hackathon in 2022, where he led a project that won “Best Overall Solution.” \\n- Pursuing AWS Certified Solutions Architect certification to enhance cloud skillset.\\n- Has expressed interest in further leadership opportunities within Insurellm and may consider project management roles in the future.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7310c9c8-03c1-4efc-a104-5e89aec6db1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1088, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd06e02f-6d9b-44cc-a43d-e1faa8acc7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2562754-9052-4aae-92c1-37236435ea06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'knowledge-base\\\\contracts\\\\Contract with Apex Reinsurance for Rellm.md', 'doc_type': 'contracts'}, page_content=\"1. **Technical Support**: Provider shall offer dedicated technical support to the Client via phone, email, and a ticketing system during business hours (Monday to Friday, 9 AM to 5 PM EST).\\n\\n2. **Training and Onboarding**: Provider will deliver comprehensive onboarding training for up to ten (10) members of the Client's staff to ensure effective use of the Rellm solution.\\n\\n3. **Updates and Maintenance**: Provider is responsible for providing updates to the Rellm platform to improve functionality and security, at no additional cost to the Client.\\n\\n4. **Escalation Protocol**: Issues that cannot be resolved at the first level of support will be escalated to the senior support team, ensuring that critical concerns are addressed promptly.\\n\\n---\\n\\n**Acceptance of Terms**: By signing below, both parties agree to the Terms, Renewal, Features, and Support outlined in this Agreement.\\n\\n**Insurellm, Inc.**  \\n_____________________________  \\nAuthorized Signature   \\nDate: ___________________\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c54b4b6-06da-463d-bee7-4dd456c2b887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document types found: contracts, employees, company, products\n"
     ]
    }
   ],
   "source": [
    "doc_types = set(chunk.metadata['doc_type'] for chunk in chunks)\n",
    "print(f\"Document types found: {', '.join(doc_types)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "128c73f7-f149-4904-a554-8140941fce0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='3. **Regular Updates:** Insurellm will offer ongoing updates and enhancements to the Homellm platform, including new features and security improvements.\n",
      "\n",
      "4. **Feedback Implementation:** Insurellm will actively solicit feedback from GreenValley Insurance to ensure Homellm continues to meet their evolving needs.\n",
      "\n",
      "---\n",
      "\n",
      "**Signatures:**\n",
      "\n",
      "_________________________________  \n",
      "**[Name]**  \n",
      "**Title**: CEO  \n",
      "**Insurellm, Inc.**\n",
      "\n",
      "_________________________________  \n",
      "**[Name]**  \n",
      "**Title**: COO  \n",
      "**GreenValley Insurance, LLC**  \n",
      "\n",
      "---\n",
      "\n",
      "This agreement represents the complete understanding of both parties regarding the use of the Homellm product and supersedes any prior agreements or communications.' metadata={'source': 'knowledge-base\\\\contracts\\\\Contract with GreenValley Insurance for Homellm.md', 'doc_type': 'contracts'}\n",
      "_________\n",
      "page_content='## Support\n",
      "\n",
      "1. **Customer Support**: Velocity Auto Solutions will have access to Insurellm’s customer support team via email or chatbot, available 24/7.  \n",
      "2. **Technical Maintenance**: Regular maintenance and updates to the Carllm platform will be conducted by Insurellm, with any downtime communicated in advance.  \n",
      "3. **Training & Resources**: Initial training sessions will be provided for Velocity Auto Solutions’ staff to ensure effective use of the Carllm suite. Regular resources and documentation will be made available online.\n",
      "\n",
      "---\n",
      "\n",
      "**Accepted and Agreed:**  \n",
      "**For Velocity Auto Solutions**  \n",
      "Signature: _____________________  \n",
      "Name: John Doe  \n",
      "Title: CEO  \n",
      "Date: _____________________  \n",
      "\n",
      "**For Insurellm**  \n",
      "Signature: _____________________  \n",
      "Name: Jane Smith  \n",
      "Title: VP of Sales  \n",
      "Date: _____________________' metadata={'source': 'knowledge-base\\\\contracts\\\\Contract with Velocity Auto Solutions for Carllm.md', 'doc_type': 'contracts'}\n",
      "_________\n",
      "page_content='# Avery Lancaster\n",
      "\n",
      "## Summary\n",
      "- **Date of Birth**: March 15, 1985  \n",
      "- **Job Title**: Co-Founder & Chief Executive Officer (CEO)  \n",
      "- **Location**: San Francisco, California  \n",
      "\n",
      "## Insurellm Career Progression\n",
      "- **2015 - Present**: Co-Founder & CEO  \n",
      "  Avery Lancaster co-founded Insurellm in 2015 and has since guided the company to its current position as a leading Insurance Tech provider. Avery is known for her innovative leadership strategies and risk management expertise that have catapulted the company into the mainstream insurance market.  \n",
      "\n",
      "- **2013 - 2015**: Senior Product Manager at Innovate Insurance Solutions  \n",
      "  Before launching Insurellm, Avery was a leading Senior Product Manager at Innovate Insurance Solutions, where she developed groundbreaking insurance products aimed at the tech sector.' metadata={'source': 'knowledge-base\\\\employees\\\\Avery Lancaster.md', 'doc_type': 'employees'}\n",
      "_________\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    if 'CEO' in chunk.page_content:\n",
    "        print(chunk)\n",
    "        print(\"_________\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
