{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c21d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date: 05.02.25\n",
    "# Note: lots of mucking around as GPT has a different format to Gem.\n",
    "# Edited and re-created code to make it work.\n",
    "\n",
    "# Basically there are a number of functions, some of which are called in the same function that makes the \n",
    "# openai api call. Gem can't work like that, so took same functions, combined them, then made them accessible\n",
    "# via single function, then when called outputs a text prompt (with all the same data as the original set up)\n",
    "# but just in a different format, that is then passed to gem to get the output. \n",
    "# Works fine. Started it up with the tester class, but i am using the free teir (15 RPM), so can't \n",
    "# complete tester. Results were looking good before ran out of api calls.\n",
    "\n",
    "# In summary, this takes a product and semantically searches a db for similar items. Those similar items\n",
    "# are passed to the llm (kind of like multi-shot prompting) and used to determine a price for the item in \n",
    "# question. Kind of cool.\n",
    "\n",
    "# The Agent stuff failed as that is still using Open AI\n",
    "\n",
    "# Date: 08.02.25\n",
    "# Note: Got agent working (canned Ed approach, and started fresh with creating the Class for the agent). \n",
    "# It now works, but has dependencies on parts of this code. I will note the required cells with -- AGENT --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f44a9-37cd-4aa5-9b20-cfc0dc8dfc0a",
   "metadata": {},
   "source": [
    "# The Price is Right\n",
    "\n",
    "Today we build a more complex solution for estimating prices of goods.\n",
    "\n",
    "1. Day 2.0 notebook: create a RAG database with our 400,000 training data\n",
    "2. Day 2.1 notebook: visualize in 2D\n",
    "3. Day 2.2 notebook: visualize in 3D\n",
    "4. Day 2.3 notebook: build and test a RAG pipeline with GPT-4o-mini\n",
    "5. Day 2.4 notebook: (a) bring back our Random Forest pricer (b) Create a Ensemble pricer that allows contributions from all the pricers\n",
    "\n",
    "Phew! That's a lot to get through in one day!\n",
    "\n",
    "## PLEASE NOTE:\n",
    "\n",
    "We already have a very powerful product estimator with our proprietary, fine-tuned LLM. Most people would be very satisfied with that! The main reason we're adding these extra steps is to deepen your expertise with RAG and with Agentic workflows.\n",
    "\n",
    "## We will go fast today! Hold on to your hat.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcdfea8-7241-46d7-a771-c0381a3e7063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- AGENT --\n",
    "# imports\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "import chromadb\n",
    "from items import Item\n",
    "from testing import Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98666e73-938e-469d-8987-e6e55ba5e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "\n",
    "load_dotenv()\n",
    "#os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a25a5cf-8f6c-4b5d-ad98-fdd096f5adf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There might be a problem with your API key? Please visit the troubleshooting notebook!\n",
      "Understood.  I await your instructions for the test.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "# MODEL = 'gpt-4o-mini'\n",
    "# openai = OpenAI()\n",
    "\n",
    "# ----- Replacing with Gem code -----\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key= api_key)\n",
    "\n",
    "message = \"this is a test only\"\n",
    "def gem_llm(message):\n",
    "  generation_config = {\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 40,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "    #\"response_mime_type\": \"application/json\",\n",
    "  }\n",
    "\n",
    "  model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,)\n",
    "\n",
    "  chat_session = model.start_chat(history=[  ])\n",
    "  response = chat_session.send_message(message)\n",
    "  return response.text\n",
    "print(gem_llm(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc696493-0b6f-48aa-9fa8-b1ae0ecaf3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- AGENT --\n",
    "# Load in the test pickle file\n",
    "# See the section \"Back to the PKL files\" in the day2.0 notebook\n",
    "# for instructions on obtaining this test.pkl file\n",
    "\n",
    "# with open('test.pkl', 'rb') as file:\n",
    "#     test = pickle.load(file)\n",
    "\n",
    "with open('test_lite.pkl', 'rb') as file:\n",
    "    test = pickle.load(file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d38a06-0c0d-4e96-94d1-35ee183416ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_context(similars, prices):\n",
    "    message = \"To provide some context, here are some other items that might be similar to the item you need to estimate.\\n\\n\"\n",
    "    for similar, price in zip(similars, prices):\n",
    "        message += f\"Potentially related product:\\n{similar}\\nPrice is ${price:.2f}\\n\\n\"\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f203b7-63b6-48ed-869b-e393b5bfcad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def messages_for(item, similars, prices):\n",
    "#     system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
    "#     user_prompt = make_context(similars, prices)\n",
    "#     user_prompt += \"And now the question for you:\\n\\n\"\n",
    "#     user_prompt += item.test_prompt().replace(\" to the nearest dollar\",\"\").replace(\"\\n\\nPrice is $\",\"\")\n",
    "#     return [\n",
    "#         {\"role\": \"system\", \"content\": system_message},\n",
    "#         {\"role\": \"user\", \"content\": user_prompt},\n",
    "#         {\"role\": \"assistant\", \"content\": \"Price is $\"}\n",
    "#     ]\n",
    "\n",
    "\n",
    "# Need to modify for Gem\n",
    "def messages_for(item, similars, prices):\n",
    "    #system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
    "    user_prompt = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
    "    user_prompt += make_context(similars, prices)\n",
    "    user_prompt += \"And now the question for you:\\n\\n\"\n",
    "    user_prompt += item.test_prompt().replace(\" to the nearest dollar\",\"\").replace(\"\\n\\nPrice is $\",\"\")\n",
    "    return [\n",
    "        #{\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"Price is $\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f405d-6e1f-4caa-b97f-1f62cd9d1ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- AGENT --\n",
    "DB = \"products_vectorstore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a1104-cd11-4361-ab25-85fb576e0582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mchromadb.telemetry.product.posthog:\u001b[0m Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "# -- AGENT --\n",
    "client = chromadb.PersistentClient(path=DB)\n",
    "collection = client.get_or_create_collection('products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e339760-96d8-4485-bec7-43fadcd30c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def description(item):\n",
    "    text = item.prompt.replace(\"How much does this cost to the nearest dollar?\\n\\n\", \"\")\n",
    "    return text.split(\"\\n\\nPrice is $\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd0c87-8bad-43d9-9461-bb69a9e0e22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "description(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f759bd2-7a7e-4c1a-80a0-e12470feca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelembed = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44dbd25-fb95-4b6b-bbbb-8da5fc817105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector(item):\n",
    "    return modelembed.encode([description(item)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd5ee47-db5d-4263-b0d9-80d568c91341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similars(item):\n",
    "    results = collection.query(query_embeddings=vector(item).astype(float).tolist(), n_results=5)\n",
    "    documents = results['documents'][0][:]\n",
    "    prices = [m['price'] for m in results['metadatas'][0][:]]\n",
    "    return documents, prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7b9ff9-fd90-4627-bb17-7c2f7bbd21f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test[1].prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b2659-cc6b-47aa-a797-dd1cd3d1d6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged cell from below into this one\n",
    "documents, prices = find_similars(test[1])\n",
    "print(make_context(documents, prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c5f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My code to replace existing\n",
    "def get_price(s):\n",
    "    s = s.replace('$','').replace(',','')\n",
    "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", s)\n",
    "    return float(match.group()) if match else 0\n",
    "\n",
    "\n",
    "def generate_message_for_item(item):\n",
    "    # Find similar items and their prices\n",
    "    results = collection.query(query_embeddings=vector(item).astype(float).tolist(), n_results=5)\n",
    "    documents = results['documents'][0][:]\n",
    "    prices = [m['price'] for m in results['metadatas'][0][:]]\n",
    "\n",
    "    # Create the context message for similar items\n",
    "    message = \"To provide some context, here are some other items that might be similar to the item you need to estimate.\\n\\n\"\n",
    "    for similar, price in zip(documents, prices):\n",
    "        message += f\"Potentially related product:\\n{similar}\\nPrice is ${price:.2f}\\n\\n\"\n",
    "    \n",
    "    # Construct the user prompt with the context and item-specific question\n",
    "    user_prompt = \"You estimate prices of items. Reply only with the price, no explanation\\n\"\n",
    "    user_prompt += \"Do NOT provide esitmates, ranages, or suggestions. Just provide your estimated price\\n\"\n",
    "    user_prompt += \"Try to be as accurate as possible, based on the examples and information you have\"\n",
    "    user_prompt += message\n",
    "    user_prompt += \"And now the question for you:\\n\\n\"\n",
    "    user_prompt += item.test_prompt().replace(\" to the nearest dollar\", \"\").replace(\"\\n\\nPrice is $\", \"\")\n",
    "    \n",
    "    # Return the complete message structure\n",
    "    # return [\n",
    "    #     {\"role\": \"user\", \"content\": user_prompt},\n",
    "    #     {\"role\": \"assistant\", \"content\": \"Price is $\"}\n",
    "    # ]\n",
    "    return user_prompt\n",
    "\n",
    "print('-'*10, 'desc', '-'*10)\n",
    "item = test[49]\n",
    "print(generate_message_for_item(item))\n",
    "a = generate_message_for_item(item)\n",
    "response = chat_session.send_message(a)\n",
    "b = get_price(response.text)\n",
    "print('-'*10, 'price', '-'*10)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7485a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_4o_mini_rag(item):\n",
    "    a = generate_message_for_item(item)\n",
    "    #response = chat_session.send_message(a)\n",
    "    response = gem_llm(a)\n",
    "    b = get_price(response)\n",
    "    return b\n",
    "print('-'*10, 'price', '-'*10)\n",
    "gpt_4o_mini_rag(test[1])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b81eca2-0b58-4fe8-9dd6-47f13ba5f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(messages_for(test[1], documents, prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a1b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can delete - not part of working code\n",
    "import google.generativeai as genai\n",
    "def gemini_flash_rag(item):\n",
    "    documents, prices = find_similars(item)\n",
    "    \n",
    "    # Construct the message content\n",
    "    messages = messages_for(item, documents, prices)\n",
    "    generate_content(messages)\n",
    "\n",
    "    # Extract reply from Gemini's response\n",
    "    reply = response.text if hasattr(response, 'text') else \"\"\n",
    "\n",
    "    return get_price(reply)\n",
    "gemini_flash_rag(test[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919cf7d-b3d3-4968-8c96-54a0da0b0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can delete - not part of working code\n",
    "import google.generativeai as genai\n",
    "def gemini_flash_rag(item):\n",
    "    documents, prices = find_similars(item)\n",
    "    \n",
    "    # Construct the message content\n",
    "    messages = messages_for(item, documents, prices)\n",
    "\n",
    "    # Configure the Gemini model\n",
    "    #model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    #model = flash\n",
    "    # response = model.generate_content(messages)\n",
    "\n",
    "    # # Extract reply from Gemini's response\n",
    "    # reply = response.text if hasattr(response, 'text') else \"\"\n",
    "    reply = chat_session.send_message(messages)\n",
    "\n",
    "\n",
    "    return get_price(reply)\n",
    "gemini_flash_rag(test[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e519e26-ff15-4425-90bb-bfbf55deb39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt_4o_mini_rag(test[1])\n",
    "print(len(test[0:25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce78741b-2966-41d2-9831-cbf8f8d176be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[1].price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d90455-ff7d-4f5f-8b8c-8e061263d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(gpt_4o_mini_rag, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d793c6d0-ce3f-4680-b37d-4643f0cd1d8e",
   "metadata": {},
   "source": [
    "## Optional Extra: Trying a DeepSeek API call instead of OpenAI\n",
    "\n",
    "If you have a DeepSeek API key, we will use it here as an alternative implementation; otherwise skip to the next section.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b6a22f-0195-47b6-8f6d-cab6ebe05742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DeepSeek using the OpenAI client python library\n",
    "\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "deepseek_via_openai_client = OpenAI(api_key=deepseek_api_key,base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7267d6-9489-4dac-a6e0-aec108e788c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added some retry logic here because DeepSeek is very oversubscribed and sometimes fails..\n",
    "\n",
    "def deepseek_api_rag(item):\n",
    "    documents, prices = find_similars(item)\n",
    "    retries = 8\n",
    "    done = False\n",
    "    while not done and retries > 0:\n",
    "        try:\n",
    "            response = deepseek_via_openai_client.chat.completions.create(\n",
    "                model=\"deepseek-chat\", \n",
    "                messages=messages_for(item, documents, prices),\n",
    "                seed=42,\n",
    "                max_tokens=8\n",
    "            )\n",
    "            reply = response.choices[0].message.content\n",
    "            done = True\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            retries -= 1\n",
    "    return get_price(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6560faf2-4dec-41e5-95e2-b2c46cdb3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_api_rag(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0578b116-869f-429d-8382-701f1c0882f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(deepseek_api_rag, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6739870f-1eec-4547-965d-4b594e685697",
   "metadata": {},
   "source": [
    "## And now to wrap this in an \"Agent\" class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7558f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d5deb3-6a2a-4484-872c-37176c5e1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.fat import fat\n",
    "#from agents.frontier_agentt1s2 import FrontierAgentt1s2\n",
    "#from agents.frontier_agent import FrontierAgent\n",
    "response = fat.gem_llm(message)  # Call the method on the instance\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efa7ba9-c2d7-4f95-8bb5-c4295bbeb01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the logs so we can see what's going on\n",
    "\n",
    "import logging\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e71fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa9211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- My agent code -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2701c070",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -- test agent (not full code, only part)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fat\n\u001b[1;32m----> 3\u001b[0m fat_instance \u001b[38;5;241m=\u001b[39m fat(\u001b[43mcollection\u001b[49m)  \u001b[38;5;66;03m# Create an instance of the class\u001b[39;00m\n\u001b[0;32m      4\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow much does this laptop cost?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m response \u001b[38;5;241m=\u001b[39m fat_instance\u001b[38;5;241m.\u001b[39mgem_llm(message)  \u001b[38;5;66;03m# Call the method on the instance\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'collection' is not defined"
     ]
    }
   ],
   "source": [
    "# -- test agent (not full code, only part)\n",
    "from agents.fat import fat\n",
    "fat_instance = fat(collection)  # Create an instance of the class\n",
    "message = \"How much does this laptop cost?\"\n",
    "response = fat_instance.gem_llm(message)  # Call the method on the instance\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c30be559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Force reload of agent (need when making change)\n",
    "import importlib\n",
    "from agents import fat\n",
    "\n",
    "importlib.reload(fat)\n",
    "from agents.fat import fat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03e78719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mfat:\u001b[0m Initializing Fat class\n",
      "\u001b[94mfat:\u001b[0m Initializing Fat class with collection\n",
      "\u001b[94msentence_transformers.SentenceTransformer:\u001b[0m Use pytorch device_name: cpu\n",
      "\u001b[94msentence_transformers.SentenceTransformer:\u001b[0m Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "\u001b[94mfat:\u001b[0m Extracted description from item\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5181d439bfda4b9abba0a0fea123ce7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mfat:\u001b[0m Generated message for item\n",
      "\u001b[94mfat:\u001b[0m Received response from LLM\n",
      "\u001b[94mfat:\u001b[0m Extracted price: 28.99\n",
      "\u001b[94mfat:\u001b[0m Estimated price: 28.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.99\n"
     ]
    }
   ],
   "source": [
    "# -- Call agent\n",
    "from agents.fat import fat\n",
    "item = test[42]\n",
    "# Initialize an instance of the class\n",
    "agent = fat(collection)\n",
    "\n",
    "# Example usage (assuming you have an Item object)\n",
    "#price_estimate = agent.gpt_4o_mini_rag(item)\n",
    "price_estimate = agent.price(item)\n",
    "\n",
    "print(price_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c5cd9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dryer Heating Element, Replacement with OEM Part Number DC47-00019A and P13312, Dryer Repair Kit Replacement for Old or Broken Heating Element, Easy to Install = $15.39>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f472ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Below is ed code (plus some of my code)-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e8dd5d-ed36-49d8-95f7-dc82e548255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent5 = fat(collection)\n",
    "#agent = FrontierAgentt1s2(collection)\n",
    "#agent = FrontierAgent(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbba962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent.price(\"Quadcast HyperX condenser mic for high quality podcasting\")\n",
    "agent5.price(\"Quadcast HyperX condenser mic for high quality podcasting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c18a06-d0f1-4ec9-8aff-ec3ca294dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.specialist_agent import SpecialistAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba672fb4-2c3e-42ee-9ea0-21bfcfc5260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent2 = SpecialistAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a97004-95b4-46ea-b12d-a4ead22fcb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent2.price(\"Quadcast HyperX condenser mic for high quality podcasting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5ddc6-baa6-4760-a430-05671847ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('are you working?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79551fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0051e435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing my agent set up..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecf64a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price(s):\n",
    "    s = s.replace('$','').replace(',','')\n",
    "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", s)\n",
    "    return float(match.group()) if match else 0\n",
    "\n",
    "def generate_message_for_item(item):\n",
    "    # Find similar items and their prices\n",
    "    results = collection.query(query_embeddings=vector(item).astype(float).tolist(), n_results=5)\n",
    "    documents = results['documents'][0][:]\n",
    "    prices = [m['price'] for m in results['metadatas'][0][:]]\n",
    "\n",
    "    # Create the context message for similar items\n",
    "    message = \"To provide some context, here are some other items that might be similar to the item you need to estimate.\\n\\n\"\n",
    "    for similar, price in zip(documents, prices):\n",
    "        message += f\"Potentially related product:\\n{similar}\\nPrice is ${price:.2f}\\n\\n\"\n",
    "    \n",
    "    # Construct the user prompt with the context and item-specific question\n",
    "    user_prompt = \"You estimate prices of items. Reply only with the price, no explanation\\n\"\n",
    "    user_prompt += \"Do NOT provide esitmates, ranages, or suggestions. Just provide your estimated price\\n\"\n",
    "    user_prompt += \"Try to be as accurate as possible, based on the examples and information you have\"\n",
    "    user_prompt += message\n",
    "    user_prompt += \"And now the question for you:\\n\\n\"\n",
    "    user_prompt += item.test_prompt().replace(\" to the nearest dollar\", \"\").replace(\"\\n\\nPrice is $\", \"\")\n",
    "    \n",
    "    # Return the complete message structure\n",
    "    # return [\n",
    "    #     {\"role\": \"user\", \"content\": user_prompt},\n",
    "    #     {\"role\": \"assistant\", \"content\": \"Price is $\"}\n",
    "    # ]\n",
    "    return user_prompt\n",
    "\n",
    "def price(item: str) -> float:\n",
    "    \"\"\"\n",
    "    Make a call to OpenAI or DeepSeek to estimate the price of the described product,\n",
    "    by looking up 5 similar products and including them in the prompt to give context\n",
    "    :param description: a description of the product\n",
    "    :return: an estimate of the price\n",
    "    \"\"\"\n",
    "\n",
    "    a = generate_message_for_item(item)\n",
    "    response = chat_session.send_message(a)\n",
    "    b = get_price(response.text)\n",
    "    return b\n",
    "item = test[1]\n",
    "price(item)\n",
    "print(price(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15ecc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a902e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
